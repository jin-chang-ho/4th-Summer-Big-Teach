{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1277 sha256=e0918a15533a920703c4d43983b2c928a9cf42764cf8268d31c7835573354c56\n",
      "  Stored in directory: c:\\users\\windows\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 네이버 사이트의 서진수 빅데이터 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): 서진수 빅데이터\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  베타뉴스2018.04.11. 빅데이터 전문가 서진수, '강사양성' 직접 나선다   해당 과정에 대한 내용은 오프라인 설명회에서 공개되며, 참가를 원하는 사람은 19일까지 온오프믹스 홈페이지(KBS 명견만리 서진수 직강 '빅데이터 전문강사 되기' 무료 세미나)를 통해 신청하면 된다. 서진수 대표에...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  중도일보2018.04.10. 빅데이터 전문가 서진수, 4차 산업혁명 시대의 가치와 준비 방법 제시   지난 6일, 성수동 카페에서 진행된 명사와의 인터뷰에서 빅데이터 전문가 서진수 대표가 4차산업혁명과 빅데이터, 미래에 대해 약 4시간 동안 다양한 이야기를 나눴다. Q. 간단하게 본인 소개 부탁 드립니다. A. 저는 고향이...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  게임포커스2015.08.10. '빅데이터 분석 전도사' 서진수 소장 \"데이터 분석, 누구나 할 수 있다\"   게임포커스는 '빅데이터 분석 전도사'로 잘 알려진 서진수 데이터컨시어지랩 연구소장을 만나 빅데이터, 빅데이터 전문가란 어떤 것인지, 그가 강연 등에서 소개한 데이터 분석 툴 'R'은 어떤 것인지 들어봤다....\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  연합뉴스2015.05.20.네이버뉴스 '빅데이터 분석 전도사' 서진수, 무료 강연 진행   ▲도서출판더알음(대표 서진수)은 빅데이터 활용과 관련해 대학교와 대학원, 회사 등에서 무료 지식특강을 진행한다고 20일 밝혔다. 입문자와 초보자를 위한 빅데이터 분석 방법을 다루는 이번 강의는 취업난을 겪고...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  SBS CNBC2015.05.18.네이버뉴스 빅데이터 전문가 서진수 청년들의 희망 멘토로 강단 서다   저자 서진수는 \"빅데이터는 앞으로 산업 분야를 가리지 않고 우리가 사는 미래를 예측할 수 있는 도구가 될 것\"이라고 예상하면서 \"데이터 분석에 입문하고자 하는 분들이나 현직에서 데이터 관련 업무를 하고 있지만...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  뉴시스2015.05.04.네이버뉴스 ‘빅데이터 분석 전도사’ 서진수 주목, 인문대생 멘토   = 데이터 관리와 분석 전문가인 서진수가 빅데이터 활용 무료강연을 펼치고 있다. 그는 데이터 관련 분야에서 15년 정도 종사하면서 다양한 기업체의 데이터베이스를 구축하고 운영, 분석해왔다. 오라클 SQL과 PL/SQL...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  서울신문5면 TOP2018.10.19.네이버뉴스 [2018 서울미래컨퍼런스] “40만개 기사 1시간 만에 크롤링… 2020년 빅데이터...   [서울신문] 2015~2018년 언론 기사 크롤링 시연 연령별·성별 관심 뉴스 한번에 보여줘 “남북관계에서도 빅데이터 활용 가능”서진수 데이터앤피플 대표4개로 분할된 커다란 화면에 작은 글씨로 된 수백개의 기사...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  뉴스12016.05.10.네이버뉴스 인공지능 시대 개막, 빅데이터 분석 세미나 ‘화제’   ㈜데이터앤피플, ㈜컨시어지소프트의 서진수 대표는 빅데이터와 머신 러닝 관련 분야 전문가로 15년의 경력을 자랑하는 베테랑이다. 서진수 대표는 지식은 널리 퍼질수록 더 가치가 있고 세상을 밝게 할 수 있다는...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  데일리한국2016.05.02. 알파고 통해 바라본 미래…빅데이터 중요성 확대   빅데이터 전문가 서진수 대표 “빅데이터와 프로그래밍 관련지식이 곧 경쟁력” 세계를 휩쓴 올 상반기 최대의 이슈 가운데 하나는 알파고와 이세돌9단의 대국이었다. 인간과 인공지능의 대결로도 풀이되는 이번 대국은...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  디지털타임스2016.04.28.네이버뉴스 인공지능 시대, 빅데이터와 프로그래밍 중요성 강조   ㈜데이터앤피플과 ㈜컨시어지소프트를 운영하는 빅데이터 전문가 서진수 대표에게 이야기를 들어보았다. 최근 KBS와 TV조선 등의 프로그램에서 빅데이터 분석 기술을 활용해 사회적 이슈를 분석하며 시청자들이...\n",
      "\n",
      "\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_2\\출력 파일\\문제1.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 1. 네이버 사이트에서 \"서진수 빅데이터\"로 검색한 후 \"뉴스\" 카테고리를 선택하여 조회된 기사들을 수집하여 txt 형식으로 저장하세요.\n",
    "\n",
    "# Step 1. 필요한 모듈을 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import sys \n",
    "\n",
    "# Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 네이버 사이트의 서진수 빅데이터 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"C:\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://www.naver.com/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'query')\n",
    "driver.find_element(By.ID,'query').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "\n",
    "# Step 5. 뉴스 선택하기\n",
    "driver.find_element(By.LINK_TEXT,'뉴스').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 6. Beautiful Soup 로 본문 내용만 추출하기\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('div','group_news').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Step 7. 표준 출력 방향을 바꾸어 txt 파일에 저장하기\n",
    "f_name = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\대학교\\\\4학년 여름방학\\\\Big_AI\\\\크롤링\\\\코드\\\\Chap_2\\\\출력 파일\\\\문제1.txt\"\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'w' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 다음 사이트의 서진수 빅데이터 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): 서진수 빅데이터\n",
      "\n",
      "\n",
      "‘인터파크-트리플’ 통합한다 [잡포스트] 서진수 기자 = 인터파크와 트리플은 각각 이사회를 열고 양사의 합병 안건을 통과시켰다. 합병 후 존속법인은 인터파크며...4월부터 야놀자의 자회사로 편입됐다. 트리플은 빅데이터를 기반으로 항공권, 호텔, 투어, 입장권 등 각종 여행상품 및 콘텐츠를...  잡포스트 2022.06.09  10301^https://cp.news.search.daum.net/p/120025498^26LLrG-A0-KK31ibRV^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^26LLrG-A0-KK31ibRV\n",
      "\n",
      "\n",
      "서울특별시관광협회, 전국광역시도관광협회 회장단협의회 기자 간담회 성료.. \"향후 지역관광 활성화에 더 힘쓸것\" 3년간의 빅데이터 분석을 통해 광역별 변화요인과 활성화 키워드 인지와 코로나 팬데믹 상황의 국민 여행 패턴 변화 인지 계기 지역별 관광 콘텐츠 개발 및 인프라 확대 차원의 아이디어 제공 기회에 대하여 논의를 하였다. 그리고, 민감한 현안인 신정부의 관광청...  디스커버리뉴스 2022.05.30  10301^https://cp.news.search.daum.net/p/119691303^26l2jduwmnsX9typgO^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^26l2jduwmnsX9typgO\n",
      "\n",
      "\n",
      "'명견만리' 초연결시대, 당신의 정보가 만들어 낸 빅데이터 혁명…프리젠터 김승주 교수 서진수 대표 데이터 전문가 서진수 대표와 함께 그 내막을 들어본다. * 프리젠터 김승주 : 고려대학교 정보보호대학원 교수 * 프리젠터 서진수 : 빅데이터 전문가 ■ 개인정보 유출 1위 국가, 대한민국! 지난주, 국내 1위 이동통신사에서 가입자 절반이 넘는 2800만 명의 개인...  라이브엔 2016.07.15  10301^https://cp.news.search.daum.net/p/47360876^265M9e0rCnIQa8l465^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^265M9e0rCnIQa8l465\n",
      "\n",
      "\n",
      "서진수 대표, 변화의 흐름을 이끄는 빅데이터 전문가 산업혁명’ 변화의 흐름을 이끄는 빅데이터 전문가 서진수 ㈜컨시어지소프트 대표 | ㈜데이터앤피플 대표 언제부터인가 미디어에서...등장하고 있다. 4차 산업혁명은 인공 지능, 사물인터넷, 빅데이터, 모바일 등 첨단 정보통신기술이 발달함에 따라 경제·사회 전반...  주간인물위클리피플 2017.08.24  10301^https://cp.news.search.daum.net/p/59256114^26JVyheIX6WbWzmPRg^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^26JVyheIX6WbWzmPRg\n",
      "\n",
      "\n",
      "'빅데이터 분석 전도사' 서진수 주목, 인문대생 멘토 【서울=뉴시스】유희연 기자 = 데이터 관리와 분석 전문가인 서진수가 빅데이터 활용 무료강연을 펼치고 있다. 그는 데이터 관련 분야에서 15년 정도 종사하면서 다양한 기업체의 데이터베이스를 구축하고 운영, 분석해왔다. 오라클 SQL과 PL/SQL, 오라클 관리실무...  뉴시스 2015.05.04 다음뉴스  10301^http://v.media.daum.net/v/20150504152121172?f=o^268BZtuxfC7fWOhRLl^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^268BZtuxfC7fWOhRLl\n",
      "\n",
      "\n",
      "빅데이터 전문가 서진수, '강사양성' 직접 나선다 과정에 대한 내용은 오프라인 설명회에서 공개되며, 참가를 원하는 사람은 19일까지 온오프믹스 홈페이지(KBS 명견만리 서진수 직강 '빅데이터 전문강사 되기' 무료 세미나)를 통해 신청하면 된다. 서진수 대표에 대한 자세한 정보는 포털에 ‘서진수 홈페이지...  베타뉴스 2018.04.11  10301^https://cp.news.search.daum.net/p/66155286^263bKe-7sS__Pl5dOU^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^263bKe-7sS__Pl5dOU\n",
      "\n",
      "\n",
      "'빅데이터 분석 전도사' 서진수, 무료 강연 진행 ▲도서출판더알음(대표 서진수)은 빅데이터 활용과 관련해 대학교와 대학원, 회사 등에서 무료 지식특강을 진행한다고 20일 밝혔다. 입문자와 초보자를 위한 빅데이터 분석 방법을 다루는 이번 강의는 취업난을 겪고 있는 인문계열 학생들을 위해 기획됐다. 최근...  연합뉴스 2015.05.20 다음뉴스  10301^http://v.media.daum.net/v/20150520111211126?f=o^268tp7EaE5MK52uHSk^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^268tp7EaE5MK52uHSk\n",
      "\n",
      "\n",
      "빅데이터 전문가 서진수, 청년 멘토로 나서 매우 어렵다. 그러므로 취업 성공을 위해서는 현직에서 전문가로 종사하고 있는 '선배'들의 조언이 큰 길잡이가 될 수 있다. 빅데이터 전문가 서진수(도서출판 더알음 대표)는 취업을 꿈꾸는 청년들의 멘토 역할을 자처한다. 대학, 기업, 관공서 등에서 강의하며...  조선일보 2015.04.20 다음뉴스  10301^http://v.media.daum.net/v/20150420130412151?f=o^26HvRH6sJOQJSCds4s^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^26HvRH6sJOQJSCds4s\n",
      "\n",
      "\n",
      "빅데이터 전문가 서진수 청년들의 희망 멘토로 강단 서다 직장인들에게 작은 도움이 되고자 여러 대학교와 대학원, 회사 등을 방문해 무료 특강을 진행하고 있는 것이다. 저자 서진수는 \"빅데이터는 앞으로 산업 분야를 가리지 않고 우리가 사는 미래를 예측할 수 있는 도구가 될 것\"이라고 예상하면서 \"데이터 분석에 입문...  SBS Biz 2015.05.18 다음뉴스  10301^http://v.media.daum.net/v/20150518133505852?f=o^26HxvVzNjpqpg_P3zh^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^26HxvVzNjpqpg_P3zh\n",
      "\n",
      "\n",
      "'빅데이터 분석 전도사' 서진수 소장 \"데이터 분석, 누구나 할 수 있다\" 빅데이터라는 말이 여기저기서 사용되고 있지만 빅데이터가 무엇인지를 아는 사람은 드물 것 같다. 빅데이터란 대체 무엇인가 서진수 소장: 빅데이터란 용어는 크다, 빠르다, 많다 등 다양한 의미를 가지고 있습니다만 더 쉽게 말하자면 우리 주변에서 우리를...  게임포커스 2015.08.10  10301^https://cp.news.search.daum.net/p/37605667^264Egw0tf8xLqg52gt^news^mediaArticle^%EC%84%9C%EC%A7%84%EC%88%98%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0^264Egw0tf8xLqg52gt\n",
      "\n",
      "\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_2\\출력 파일\\문제2.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 2. 다음 사이트에서 \"서진수 빅데이터\"로 검색한 후 \"뉴스\" 카테고리를 선택하여 조회된 기사들을 수집하여 txt 형식으로 저장하세요.\n",
    "\n",
    "# Step 1. 필요한 모듈을 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import sys \n",
    "\n",
    "# Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 다음 사이트의 서진수 빅데이터 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"C:\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://www.daum.net/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'q')\n",
    "driver.find_element(By.ID,'q').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "\n",
    "# Step 5. 뉴스 선택하기\n",
    "driver.find_element(By.LINK_TEXT,'뉴스').click()\n",
    "time.sleep(4)\n",
    "\n",
    "# Step 6. Beautiful Soup 로 본문 내용만 추출하기\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('ul','list_news').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Step 7. 표준 출력 방향을 바꾸어 txt 파일에 저장하기\n",
    "f_name = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\대학교\\\\4학년 여름방학\\\\Big_AI\\\\크롤링\\\\코드\\\\Chap_2\\\\출력 파일\\\\문제2.txt\"\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'w' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 한국관광공사 사이트의 제주도 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): 제주도\n",
      "\n",
      "\n",
      "1제주도\n",
      "\n",
      "\n",
      "2계곡\n",
      "\n",
      "\n",
      "3부산\n",
      "\n",
      "\n",
      "4강원도\n",
      "\n",
      "\n",
      "5여수\n",
      "\n",
      "\n",
      "6속초\n",
      "\n",
      "\n",
      "7경기도\n",
      "\n",
      "\n",
      "8경주\n",
      "\n",
      "\n",
      "9포항\n",
      "\n",
      "\n",
      "10서울\n",
      "\n",
      "\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_2\\출력 파일\\문제3.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 3. 한국관광공사 사이트에서 \"제주도\"로 검색한 후 \"어제의 인기 검색어\" 카테고리 데이터를 수집하여 txt 형식으로 저장하세요.\n",
    "\n",
    "# Step 1. 필요한 모듈을 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import sys \n",
    "\n",
    "# Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 한국관광공사 사이트의 제주도 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"C:\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://korean.visitkorea.or.kr/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'inp_search')\n",
    "driver.find_element(By.ID,'inp_search').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Step 5. Beautiful Soup 로 본문 내용만 추출하기\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('ul',id='p_search').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Step 6. 표준 출력 방향을 바꾸어 txt 파일에 저장하기\n",
    "f_name = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\대학교\\\\4학년 여름방학\\\\Big_AI\\\\크롤링\\\\코드\\\\Chap_2\\\\출력 파일\\\\문제3.txt\"\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'w' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 한국관광공사 사이트의 제주도 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): 제주도\n",
      "\n",
      "\n",
      "자연 속에서 더욱 단단해지는 가족애, 제주돌문화공원과 교래자연휴양림   제주도 제주시    #2022년3월추천가볼만한곳#3월추천가볼만한곳#추천가볼만한곳#제주가볼만한곳#제주돌문화공원#교래자연휴양림#스누피가든#아부오름#하도리별방진#가시리유채꽃단지#사려니숲무장애나눔길#BTS#bts여행#bts투어#bts지민#제주도#공공누리 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "겨울에 만나는 초록빛 곶자왈, 제주 청수마을   제주도 제주시    #2022년2월추천가볼만한곳#2월추천가볼만한곳#추천가볼만한곳#제주가볼만한곳#청수마을#예술곶#용수항#성김대건신부제주표착기념관#자구내포구#차귀도#수월봉#공공누리#겨울여행#제주도 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "'효리네 민박'의 색다른 변신! 감성 넘치는 제주 로컬 소품샵 소길별하   제주도 제주시    #제주여행#제주가볼만한곳#효리네민박#효리네민박여행#소품샵#제주소품샵#소길별하#도치돌알파카목장#알파카#알파카목장#고배기동산#공공누리 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "[국내 트레킹 추천] 제주 올레길 걷기 여행, 준비부터 코스 선택까지 꿀팁 총정리!   제주도    #제주올레길#트레킹코스#트레킹#제주가볼만한곳#제주여행#걷기여행 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "탄소 없는 섬, 제주의 미래를 만나다_제주CFI에너지미래관   제주도 제주시    #2021_산업관광12선#제주CFI에너지미래관#제주가볼만한곳#산업관광지#신재생에너지 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "제주도 조천읍 버킷리스트 여행지 작성하기   제주도 제주시    #제주여행#제주가볼만한곳#스위스마을#제주스위스마을#교래자연휴양림#자연휴양림#산굼부리#제주산굼부리#해안누리길#닭머르해안길 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "나만 알고 싶은 제주 액티비티 ① 원시 숲과 벵뒤못과 밀리터리 카, 어디에도 없던 리얼 오프로드의 세계   제주도 제주시    #제주여행#제주가볼만한곳#액티비티#액티비티여행#체험여행#오프로드체험#제라진캠프#숲#웃밤오름#방송촬영지#촬영지#CF촬영지#공공누리#제주도 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "김창열의 회귀 철학을 건축으로 표현한 미술관, 제주도립김창열미술관   제주도 제주시    #2021년4월추천가볼만한곳#4월추천가볼만한곳#추천가볼만한곳#4월가볼만한곳#제주여행#제주가볼만한곳#미술관#제주도립김창열미술관#김창열미술관#제주현대미술관#성이시돌목장#왕이메오름#숲길#공공누리#봄에아름다운건축물 더보기  즐겨찾기 공유하기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "내 위치에서459.1 Km     제주 방선문축제 (신선이 머무는 곳)   제주도 제주시    #방선문축제#제주권#가볼만한축제#아이와함께#친구와함께#연인과함께#가족여행#체험학습#데이트코스#이색체험#나들이#힐링#섬여행#자연좋은곳#축제 더보기  즐겨찾기 공유하기 코스에 담기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "코스에 담기\n",
      "\n",
      "\n",
      "내 위치에서469.2 Km     제주 튤립축제 in 한림공원   제주도 제주시    #한림공원튤립축제#제주권#가볼만한축제#아이와함께#친구와함께#연인과함께#가족여행#체험학습#데이트코스#섬여행#이색체험#나들이#힐링#자연좋은곳#꽃축제#관광지#봄꽃#축제#봄꽃여행 더보기  즐겨찾기 공유하기 코스에 담기\n",
      "\n",
      "\n",
      "즐겨찾기\n",
      "\n",
      "\n",
      "공유하기\n",
      "\n",
      "\n",
      "코스에 담기\n",
      "\n",
      "\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_2\\출력 파일\\문제4.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 4. 한국관광공사 사이트에서 \"제주도\"로 검색한 후 \"어제의 인기 검색어\" 카테고리 데이터를 수집하여 txt 형식으로 저장하세요.\n",
    "\n",
    "# Step 1. 필요한 모듈을 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import sys \n",
    "\n",
    "# Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 한국관광공사 사이트의 제주도 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 해양자원): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"C:\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://korean.visitkorea.or.kr/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'inp_search')\n",
    "driver.find_element(By.ID,'inp_search').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Step 5. Beautiful Soup 로 본문 내용만 추출하기\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('ul', 'list_thumType type1').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Step 6. 표준 출력 방향을 바꾸어 txt 파일에 저장하기\n",
    "f_name = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\대학교\\\\4학년 여름방학\\\\Big_AI\\\\크롤링\\\\코드\\\\Chap_2\\\\출력 파일\\\\문제4.txt\"\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'w' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
