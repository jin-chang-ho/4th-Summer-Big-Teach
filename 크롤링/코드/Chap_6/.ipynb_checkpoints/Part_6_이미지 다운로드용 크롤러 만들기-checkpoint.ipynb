{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 휴넷 사이트의 강의 자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(예: 파이썬): 파이썬\n",
      "2.수집할 건수는 총 몇건입니까?(기본값:10): 2\n",
      "화면을 끄겠습니다.\n"
     ]
    },
    {
     "ename": "UnexpectedAlertPresentException",
     "evalue": "Alert Text: 마지막 페이지입니다.\nMessage: unexpected alert open: {Alert text : 마지막 페이지입니다.}\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00BF6463+2188387]\n\tOrdinal0 [0x00B8E461+1762401]\n\tOrdinal0 [0x00AA3D78+802168]\n\tOrdinal0 [0x00AFCA92+1165970]\n\tOrdinal0 [0x00AEC5F6+1099254]\n\tOrdinal0 [0x00AC6BE0+945120]\n\tOrdinal0 [0x00AC7AD6+948950]\n\tGetHandleVerifier [0x00E971F2+2712546]\n\tGetHandleVerifier [0x00E8886D+2652765]\n\tGetHandleVerifier [0x00C8002A+520730]\n\tGetHandleVerifier [0x00C7EE06+516086]\n\tOrdinal0 [0x00B9468B+1787531]\n\tOrdinal0 [0x00B98E88+1805960]\n\tOrdinal0 [0x00B98F75+1806197]\n\tOrdinal0 [0x00BA1DF1+1842673]\n\tBaseThreadInitThunk [0x76CDFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77AA7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77AA7A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnexpectedAlertPresentException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a4573194d2da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mimg_src\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ul'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'vod_list'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    930\u001b[0m                 \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \"\"\"\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    432\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;34m'alert'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnexpectedAlertPresentException\u001b[0m: Alert Text: 마지막 페이지입니다.\nMessage: unexpected alert open: {Alert text : 마지막 페이지입니다.}\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00BF6463+2188387]\n\tOrdinal0 [0x00B8E461+1762401]\n\tOrdinal0 [0x00AA3D78+802168]\n\tOrdinal0 [0x00AFCA92+1165970]\n\tOrdinal0 [0x00AEC5F6+1099254]\n\tOrdinal0 [0x00AC6BE0+945120]\n\tOrdinal0 [0x00AC7AD6+948950]\n\tGetHandleVerifier [0x00E971F2+2712546]\n\tGetHandleVerifier [0x00E8886D+2652765]\n\tGetHandleVerifier [0x00C8002A+520730]\n\tGetHandleVerifier [0x00C7EE06+516086]\n\tOrdinal0 [0x00B9468B+1787531]\n\tOrdinal0 [0x00B98E88+1805960]\n\tOrdinal0 [0x00B98F75+1806197]\n\tOrdinal0 [0x00BA1DF1+1842673]\n\tBaseThreadInitThunk [0x76CDFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77AA7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77AA7A6E+238]\n"
     ]
    }
   ],
   "source": [
    "#17. 이미지 다운로드용 웹크롤러 만들기\n",
    "# Step 1. 필요한 모듈과 라이브러리를 로딩하고 검색어를 입력 받습니다\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request # 이미지 주소로 이미지를 다운받는 모듈\n",
    "import urllib.parse # 한글을 변환해주는 모듈\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 휴넷 사이트의 강의 자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 파이썬): ')\n",
    "\n",
    "try :\n",
    "    cnt = int(input('2.수집할 건수는 총 몇건입니까?(기본값:10): '))\n",
    "except ValueError :\n",
    "    cnt = 10\n",
    "    print('기본값인 10 건으로 수집을 진행합니다.')\n",
    "page_cnt = math.ceil( cnt / 12)\n",
    "\n",
    "f_dir = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\대학교\\\\4학년 여름방학\\\\Big_AI\\\\크롤링\\\\코드\\\\Chap_6\\\\출력 파일\\\\\"\n",
    "\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"C:\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://www.hunet.co.kr/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'txtKeyword')\n",
    "driver.find_element(By.ID,'txtKeyword').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "\n",
    "#Step 5. 사용자가 요청한 건수만큼 더보기 클릭하기\n",
    "for a in range(0,page_cnt) :\n",
    "    try :\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"divEducationList\"]/div/div[2]/div[5]/a[1]').click()\n",
    "        time.sleep(5)\n",
    "        try :\n",
    "            result = driver.switch_to_alert() # alert 창으로 가라.\n",
    "            result.accept() # 확인 버튼을 눌려라.\n",
    "        except :\n",
    "            continue\n",
    "    except :\n",
    "        print('페이지 이동이 끝났습니다. 이제 데이터를 수집하겠습니다')\n",
    "        break\n",
    "    \n",
    "# Step 6. 이미지 추출하여 저장하기 \n",
    "file_no = 0                                \n",
    "count = 1\n",
    "img_src2=[]  # 이미지 원본 URL 주소 저장할 리스트\n",
    "\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "img_dir = f_dir+s+'-'+query_txt\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)\n",
    "\n",
    "time.sleep(2)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "img_src = soup.find('ul','vod_list').find_all('img')\n",
    "\n",
    "for i in img_src :\n",
    "    img_src1=i['src']\n",
    "    img_src2.append(img_src1)\n",
    "    print(img_src1)\n",
    "    count += 1\n",
    "    if count > cnt :\n",
    "        break\n",
    "\n",
    "for i in range(0,len(img_src2)) :\n",
    "    file_no += 1 \n",
    "     # 설정한 이미지주소(절대 한글 x!!)로 사진을 받아 설정한 경로에 저장한다.\n",
    "    urllib.request.urlretrieve(urllib.parse.quote(img_src2[i].encode('utf8'), '/:'),str(file_no)+'.jpg')\n",
    "\n",
    "    time.sleep(0.5)      \n",
    "    print(\"%s 번째 이미지 저장중입니다=======\" %file_no)\n",
    "\n",
    "# Step 7. 요약 정보를 출력합니다                \n",
    "print(\"=\" *70)\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %file_no)\n",
    "print(\"파일 저장 경로: %s 입니다\" %img_dir)\n",
    "print(\"=\" *70)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " pixabay 사이트에서 이미지를 검색하여 수집하는 크롤러 입니다 \n",
      "================================================================================\n",
      "1.크롤링할 이미지의 키워드는 무엇입니까?: 고양이\n",
      "2.크롤링 할 건수는 몇건입니까?: 20\n",
      "3.파일이 저장될 경로만 쓰세요(예: c:\\py_temp\\ ) : \n",
      "\n",
      "\n",
      "요청하신 데이터를 수집 중이오니 잠시만 기다려 주세요~~^^\n",
      "https://cdn.pixabay.com/photo/2014/11/30/14/11/cat-551554__480.jpg\n",
      "https://cdn.pixabay.com/photo/2015/04/23/21/59/tree-736877__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/02/20/18/03/cat-2083492__340.jpg\n",
      "https://cdn.pixabay.com/photo/2014/04/13/20/49/cat-323262__340.jpg\n",
      "https://cdn.pixabay.com/photo/2015/11/16/14/43/cat-1045782__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/07/25/01/22/cat-2536662__340.jpg\n",
      "https://cdn.pixabay.com/photo/2015/03/27/13/16/maine-coon-694730__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/11/09/21/41/cat-2934720__340.jpg\n",
      "https://cdn.pixabay.com/photo/2018/10/01/09/21/pets-3715733__340.jpg\n",
      "https://cdn.pixabay.com/photo/2016/03/28/12/35/cat-1285634__340.png\n",
      "https://cdn.pixabay.com/photo/2021/10/19/10/56/cat-6723256__340.jpg\n",
      "https://cdn.pixabay.com/photo/2014/12/22/10/04/lions-577104__340.jpg\n",
      "https://cdn.pixabay.com/photo/2013/05/30/18/21/cat-114782__340.jpg\n",
      "https://cdn.pixabay.com/photo/2016/07/21/14/18/dog-1532627__340.png\n",
      "https://cdn.pixabay.com/photo/2016/02/10/16/37/cat-1192026__340.jpg\n",
      "https://cdn.pixabay.com/photo/2019/11/08/11/56/cat-4611189__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/07/24/19/57/tiger-2535888__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/10/25/16/54/african-lion-2888519__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/12/11/15/34/lion-3012515__340.jpg\n",
      "https://cdn.pixabay.com/photo/2017/11/14/13/06/kitty-2948404__340.jpg\n",
      "1 페이지에서 1 번째 이미지 저장중입니다=======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:94: DeprecationWarning: AppURLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 페이지에서 2 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 3 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 4 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 5 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 6 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 7 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 8 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 9 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 10 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 11 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 12 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 13 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 14 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 15 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 16 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 17 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 18 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 19 번째 이미지 저장중입니다=======\n",
      "1 페이지에서 20 번째 이미지 저장중입니다=======\n",
      "======================================================================\n",
      "총 소요시간은 29.9 초 입니다 \n",
      "총 저장 건수는 20 건 입니다 \n",
      "파일 저장 경로: c:\\py_temp\\2022-03-24-11-53-15-고양이 입니다\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Case 2. pixapay 사이트에서 그림 수집하기\n",
    "# Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import urllib.request\n",
    "import urllib\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "#Step 2. 필요한 정보를 입력 받습니다.\n",
    "print(\"=\" *80)\n",
    "print(\" pixabay 사이트에서 이미지를 검색하여 수집하는 크롤러 입니다 \")\n",
    "print(\"=\" *80)\n",
    "\n",
    "query_txt = input('1.크롤링할 이미지의 키워드는 무엇입니까?: ')\n",
    "cnt = int(input('2.크롤링 할 건수는 몇건입니까?: '))\n",
    "real_cnt = math.ceil(cnt / 100) # 실제 크롤링 할 페이지 수\n",
    "f_dir=input('3.파일이 저장될 경로만 쓰세요(예: c:\\\\py_temp\\\\ ) : ')\n",
    "if f_dir =='' :\n",
    "    f_dir = \"c:\\\\py_temp\\\\\"\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"요청하신 데이터를 수집 중이오니 잠시만 기다려 주세요~~^^\")\n",
    "\n",
    "#Step 3. 파일을 저장할 폴더를 생성합니다\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "img_dir = f_dir+s+'-'+query_txt\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)      \n",
    "\n",
    "#Step 4. 크롬 드라이버를 사용해서 웹 브라우저를 실행한 후 검색합니다\n",
    "s_time = time.time( )\n",
    "\n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "driver.get('https://pixabay.com/ko/')\n",
    "time.sleep(3)\n",
    "\n",
    "# 검색어 입력 창에 검색어 입력 후 검색 수행\n",
    "element = driver.find_element(By.NAME,'q')\n",
    "element.send_keys(query_txt)\n",
    "element.submit()\n",
    "\n",
    "# Step 5. 이미지 추출하여 저장하기 \n",
    "file_no = 1\n",
    "count = 1\n",
    "img_src2=[]    #이미지 파일의 url 주소 저장용 리스트\n",
    "\n",
    "# 스크롤 다운 함수 만들기\n",
    "def scroll_down(driver):\n",
    "    #driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "for a in range(1 , real_cnt+1):  \n",
    "    \n",
    "    for b in range(0,5):\n",
    "        scroll_down(driver)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # 원본 이미지 url 주소 수집 \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')    \n",
    "    img_src = soup.find('div','container--HcTw2').find_all('img')\n",
    "    \n",
    "    for c in img_src :\n",
    "        img_src1=c['src']\n",
    "        \n",
    "        if 'http' in img_src1 :\n",
    "            img_src2.append(img_src1)\n",
    "            print(img_src1)\n",
    "            \n",
    "        count += 1  \n",
    "        \n",
    "        if count > cnt :\n",
    "            break\n",
    "            \n",
    "    #수집된 url 주소로 이미지 파일 가져와서 저장하기 (자격증명)\n",
    "    for e in range(0,len(img_src2)) :\n",
    "\n",
    "        class AppURLopener(urllib.request.FancyURLopener):\n",
    "            version = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                       Chrome/47.0.2526.69 Safari/537.36\"\n",
    "\n",
    "        urllib.urlopener = AppURLopener()\n",
    "        urllib.urlopener.retrieve(img_src2[e],str(file_no)+'.jpg')\n",
    "\n",
    "        print(\"%s 페이지에서 %s 번째 이미지 저장중입니다=======\" %(a,file_no))\n",
    "\n",
    "        time.sleep(0.5) \n",
    "\n",
    "        if file_no >= cnt :\n",
    "                break\n",
    "\n",
    "        file_no += 1  \n",
    "                \n",
    "    if a > real_cnt :\n",
    "        break\n",
    "\n",
    "# Step 6. 요약 정보를 출력합니다                \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *70)\n",
    "print(\"총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %file_no)\n",
    "print(\"파일 저장 경로: %s 입니다\" %img_dir)\n",
    "print(\"=\" *70)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
