{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "인스타그램 해쉬태그와 이미지 수집하기\n",
      "================================================================================\n",
      "1.검색할 해쉬태그를 입력하세요(예: 강남맛집): 강남맛집\n",
      "2.수집할 건수는 총 몇건입니까?(기본값:10): 9\n",
      "\n",
      "\n",
      "요청하신 데이터를 추출중이오니 잠시만 기다려 주세요~~~~^^\n",
      "\n",
      "\n",
      "요청하신 데이터를 수집중이니 잠시만 기다려 주세요~^^\n",
      "\n",
      "요청하신 데이터를 수집중이니 잠시만 더 기다려 주세요~^^\n",
      "1번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/Cf0N5ioNkWg/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 1번째 이미지 저장 완료===\n",
      "['#잠실', '#잠실데이트', '#잠실데이트코스', '#잠실맛집', '#잠실맛집추천', '#잠실카페', '#잠실술집', '#잠실가볼만한곳', '#강남맛집', '#강남맛집추천', '#강남술집', '#석촌호수맛집', '#송파구맛집', '#송파구술집', '#송파나루맛집', '#송리단길맛집', '#송리단길술집', '#송리단길데이트', '#석촌호수술집', '#데이트코스추천', '#데이트코스', '#칵테일바', '#서울칵테일바추천', '#칵테일바추천']\n",
      "2번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/CfxpGwaNOsW/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 2번째 이미지 저장 완료===\n",
      "['#1일1카페', '#무니', '#무니', '#압구정카페', '#무니', '#1일1캎', '#1일1캎_서울', '#강남카페', '#서울카페', '#압구정무니', '#서울무니카페', '#쉐이크맛집', '#크로넛맛집', '#빵지순례', '#압구정로데오카페', '#서울무니', '#서울핫플', '#디저트카페', '#강남디저트', '#강남맛집', '#강남카페맛집', '#압구정카페맛집', '#유럽풍건물카페', '#강남명소', '#강남가볼만한곳', '#감성카페', '#국내카페', '#국내카페추천']\n",
      "3번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/Cfvt2SIldXQ/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 3번째 이미지 저장 완료===\n",
      "['#교다이야', '#합정맛집', '#우동맛집', '#냉우동맛집', '#붓카케우동', '#일식맛집', '#합정데이트']\n",
      "4번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/Cf1I4gLFFfZ/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 4번째 이미지 저장 완료===\n",
      "['#남산터신논현점', '#강남맛집', '#강남역맛집', '#강남밥집', '#강남부대찌개', '#강남점심', '#강남술집', '#강남역술집', '#강남회식', '#강남모임장소', '#강남데이트', '#신논현맛집', '#신논현역맛집', '#신논현밥집', '#신논현부대찌개', '#부대찌개맛집', '#부찌맛집', '#해장맛집', '#남산터']\n",
      "5번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/CfxoQD4B5fi/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 5번째 이미지 저장 완료===\n",
      "['#내궁맛집_신사', '#신사동맛집', '#압구정맛집', '#압구정로데오맛집', '#강남맛집', '#오마카세맛집', '#키이로']\n",
      "6번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/CfwCEPilVZo/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 6번째 이미지 저장 완료===\n",
      "['#플매_강남', '#육품', '#서울맛집', '#서울여행', '#강남맛집', '#강남역맛집', '#서초맛집', '#서초동맛집', '#먹스타그램', '#맛스타그램', '#고기맛집']\n",
      "7번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/Cf1Tk6kFzot/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 7번째 이미지 저장 완료===\n",
      "['#선릉', '#오봉집', '#투어_선릉', '#선릉맛집', '#선릉역', '#선릉역맛집', '#선릉술집', '#강남', '#강남맛집', '#술안주', '#독도소주', '#소주', '#낙지볶음', '#칼국수', '#낙지', '#밥반찬', '#밥도둑', '#술스타그램', '#먹팔', '#먹스타그램', '#주먹밥', '#직화', '#쭈꾸미', '#막국수', '#강남술집']\n",
      "8번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/Cf0RVNmDVI4/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 8번째 이미지 저장 완료===\n",
      "['#스테이터', '#강남', '#스테이터', '#강남맛집', '#강남맛집추천', '#강남데이트코스', '#강남데이트코스추천', '#가성비스테이크', '#파스타맛집', '#육회비빔밥', '#고기맛집', '#스테이크맛집', '#강남고기맛집', '#강남스테이크맛집', '#서울맛집추천', '#신논현맛집', '#신논현역맛집', '#신논현역맛집추천', '#신논현맛집추천', '#먹팔', '#맞팔', '#소통', '#먹소통']\n",
      "9번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~\n",
      "게시물 URL: https://www.instagram.com/p/Cf0mjbNvDcs/\n",
      "C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image  아래에 9번째 이미지 저장 완료===\n",
      "['#제주성산맛집', '#강남맛집']\n",
      "========================================================================================================================\n",
      "1.총 소요시간: 96.3 초\n",
      "2.총 저장 건수: 10 건 \n",
      "3.csv파일 저장 경로: C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\2022-07-11-00-51-42-강남맛집-인스타그램.csv\n",
      "4.xls파일 저장 경로: C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\2022-07-11-00-51-42-강남맛집-인스타그램.xlsx\n",
      "5.이미지파일 저장 경로: C:\\Users\\Windows\\Desktop\\대학교\\4학년 여름방학\\Big_AI\\크롤링\\코드\\Chap_7\\출력 파일\\2022-07-11-00-51-42-강남맛집-인스타그램\\image\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# 인스타 그램의 사진과 해쉬태그 수집하기 \n",
    "##########################################################################\n",
    "#Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import unicodedata # 인스타그램의 해시태그 수집 중 자음/모음 분리현상 방지용 모듈(인스타그램에서 파일 수정 시 자음, 모음 분리됨)\n",
    "import urllib.request\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import pyautogui\n",
    "\n",
    "#Step 2. 사용자에게 필요한 정보들을 입력 받기\n",
    "print(\"=\" *80)\n",
    "print(\"인스타그램 해쉬태그와 이미지 수집하기\")\n",
    "print(\"=\" *80)\n",
    "\n",
    "v_id = \"ckdgh8204\"\n",
    "v_passwd = \"thvmxm2017!\"\n",
    "query_txt = input(\"1.검색할 해쉬태그를 입력하세요(예: 강남맛집): \")\n",
    "try :\n",
    "    cnt = int( input('2.수집할 건수는 총 몇건입니까?(기본값:10): '))\n",
    "except ValueError :\n",
    "    cnt = 10\n",
    "    print('기본값인 10 건으로 수집을 진행합니다.')\n",
    "page_cnt = math.ceil( cnt / 10)\n",
    "f_dir = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\대학교\\\\4학년 여름방학\\\\Big_AI\\\\크롤링\\\\코드\\\\Chap_7\\\\출력 파일\\\\\"\n",
    "\n",
    "#Step 3.결과를 저장할 폴더명과 파일명을 설정하고 폴더를 생성하기\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "sec_name='인스타그램'\n",
    "img_dir = f_dir+s+'-'+query_txt+'-'+sec_name+'\\\\'+'image'\n",
    "\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)\n",
    "\n",
    "fc_name=f_dir+s+'-'+query_txt+'-'+sec_name+'\\\\'+s+'-'+query_txt+'-'+sec_name+'.csv'\n",
    "fx_name=f_dir+s+'-'+query_txt+'-'+sec_name+'\\\\'+s+'-'+query_txt+'-'+sec_name+'.xlsx'\n",
    "\n",
    "# Step 4. 인스타그램 접속 후 자동 로그인 하기\n",
    "s_time = time.time( )\n",
    "s = Service(\"C:\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "url = \"https://www.instagram.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"요청하신 데이터를 추출중이오니 잠시만 기다려 주세요~~~~^^\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#ID와 비번 입력후 로그인하기(입력 시 시간을 좀 줘야 안 튕긴다.)\n",
    "eid = driver.find_element(By.NAME,'username')\n",
    "for a in v_id :\n",
    "        eid.send_keys(a)\n",
    "        time.sleep(0.3)\n",
    "epwd = driver.find_element(By.NAME,'password')\n",
    "for b in v_passwd :\n",
    "        epwd.send_keys(b)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"loginForm\"]/div/div[3]/button/div').click()\n",
    "time.sleep(6)\n",
    "\n",
    "# Step 5. 검색할 해쉬태그 입력하기\n",
    "hashtag_link = url + \"explore/tags/\" + str(query_txt) + \"/\" # 사이트로 들어가기\n",
    "driver.get(hashtag_link)\n",
    "time.sleep(5)\n",
    "\n",
    "# Step 6. 전체 게시물의 원본 URL 추출하기\n",
    "item=[]     # 인스타그램 URL 주소 저장할 리스트\n",
    "item2=[]    # 중복값을 제거한 최종 URL 주소를 저장할 리스트\n",
    "\n",
    "# 자동 스크롤다운 함수\n",
    "def scroll_down(driver):\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print('요청하신 데이터를 수집중이니 잠시만 기다려 주세요~^^')\n",
    "print()\n",
    "\n",
    "a = 1\n",
    "\n",
    "while (a <= page_cnt):\n",
    "    scroll_down(driver)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    all_a = soup.find('main','_a993 _a995').find_all('a')\n",
    "\n",
    "    for i in all_a:    \n",
    "        url = i['href']\n",
    "        url = 'https://www.instagram.com' + url\n",
    "        item.append(url)       \n",
    "        item2 = pd.Series(item).drop_duplicates()\n",
    "    \n",
    "        if len(item2) >= cnt :\n",
    "            break\n",
    "    a += 1\n",
    "    \n",
    "print('요청하신 데이터를 수집중이니 잠시만 더 기다려 주세요~^^')\n",
    "\n",
    "#Step 7. 각 페이지별로 이미지와 해쉬태그를 수집하기\n",
    "count = 1     # 추출 데이터 건수 세기\n",
    "no2= []       # 번호 저장\n",
    "url2=[]       # 수집완료된 url 저장\n",
    "hash2 = []    # 해쉬 태그 저장 \n",
    "\n",
    "count = 1\n",
    "\n",
    "for item in item2:\n",
    "    driver.get(item)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = soup.find('div','_a9zs')\n",
    "\n",
    "    try :\n",
    "        tags_1 = tags.find_all('a')\n",
    "    except :\n",
    "        continue\n",
    "    else :\n",
    "        print('%s번째 게시물의 대표 이미지와 해쉬태그를 수집합니다~~~' % count)\n",
    "        print('게시물 URL:' , item)\n",
    "        no2.append(count)\n",
    "        url2.append(c)\n",
    "        \n",
    "        #해당 페이지의 대표 이미지 수집\n",
    "        img_src = soup.find('div','_aagv').find('img')['src']\n",
    "        urllib.request.urlretrieve(img_src, str(count)+'.jpg')\n",
    "        print(img_dir,' 아래에 %s번째 이미지 저장 완료===' % count)\n",
    "\n",
    "        # 해당 페이지의 해시태그 수집\n",
    "        # 비트맵 이미지 아이콘을 위한 대체 딕셔너리를 만들기\n",
    "        import sys\n",
    "        \n",
    "        bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "\n",
    "        hash_tags=[]\n",
    "        for d in tags_1 :\n",
    "            tags = d.get_text()\n",
    "            tags_11 = tags.translate(bmp_map) # 저장이 안되는 것들을 바꿔준다.\n",
    "            tags_2 = unicodedata.normalize('NFC', tags_11) # 자음, 모음 분리 현상을 해결해준다.\n",
    "                      \n",
    "            if tags_2[0:1]=='#': # 해시태그일 때\n",
    "                hash_tags.append(tags_2) # 저장\n",
    "                \n",
    "        print(hash_tags)       \n",
    "        hash2.append(hash_tags)  # 각 게시물의 해시태그를 1줄의 리스트 형태로 저장하기\n",
    "        \n",
    "    count += 1\n",
    "    \n",
    "\n",
    "#Step 8. 수집된 해시태그를 csv , xls 형식으로 저장하기\n",
    "# xls , csv로 저장하기 위해 데이터 프레임 생성하기\n",
    "insta = pd.DataFrame( )\n",
    "insta['번호'] = no2\n",
    "insta['URL주소'] = url2\n",
    "insta['해쉬태그'] = pd.Series(hash2)\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "insta.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "insta.to_excel(fx_name ,index=False , engine='openpyxl')\n",
    "\n",
    "#Step 9. 요약 정보 출력하기    \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *120)\n",
    "print(\"1.총 소요시간: %s 초\" %round(t_time,1))\n",
    "print(\"2.총 저장 건수: %s 건 \" %count)\n",
    "print(\"3.csv파일 저장 경로: %s\" %fc_name)\n",
    "print(\"4.xls파일 저장 경로: %s\" %fx_name)\n",
    "print(\"5.이미지파일 저장 경로: %s\" %img_dir)\n",
    "print(\"=\" *120)\n",
    "\n",
    "driver.close( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
